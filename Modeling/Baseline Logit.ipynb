{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import seaborn \n",
    "import openpyxl\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, auc, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Loan_default.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances where Default is 1: 29653\n"
     ]
    }
   ],
   "source": [
    "default_count = df['Default'].sum()\n",
    "\n",
    "print(f\"Number of instances where Default is 1: {default_count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with class imbalance\n",
    "\n",
    "Using a binomial model, we assume a 0.5 probability of the outcome variable. As in our sample, we have a roughly 0.12 probability of default, we may consider balancing the sample such that the default probability of 0.5\n",
    "\n",
    "To do that, we randomly sample from the observations of no-default (downward) such that the default and no-default are matched in size."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling\n",
    "\n",
    "I do admit, this is wholly pulled from ChatGPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the majority and minority classes\n",
    "majority_class = df[df['Default'] == 0]\n",
    "minority_class = df[df['Default'] == 1]\n",
    "\n",
    "# Downsample the majority class to match the number of instances in the minority class\n",
    "downsampled_majority = majority_class.sample(n=len(minority_class), random_state=9112023)\n",
    "\n",
    "# Combine the downsampled majority class with the original minority class\n",
    "balanced_df = pd.concat([downsampled_majority, minority_class])\n",
    "\n",
    "y = balanced_df['Default']\n",
    "\n",
    "# Shuffle the rows to mix the classes\n",
    "df = balanced_df.sample(frac=1, random_state=9112023).reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying that the balanced_df is indeed holding a 50/50 split between default and no-default observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>MonthsEmployed</th>\n",
       "      <th>NumCreditLines</th>\n",
       "      <th>InterestRate</th>\n",
       "      <th>LoanTerm</th>\n",
       "      <th>DTIRatio</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.492008</td>\n",
       "      <td>77943.901241</td>\n",
       "      <td>135176.603463</td>\n",
       "      <td>567.161366</td>\n",
       "      <td>55.446903</td>\n",
       "      <td>2.538917</td>\n",
       "      <td>14.555326</td>\n",
       "      <td>36.018008</td>\n",
       "      <td>0.506626</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.950919</td>\n",
       "      <td>40121.124420</td>\n",
       "      <td>70906.740030</td>\n",
       "      <td>158.973285</td>\n",
       "      <td>34.559096</td>\n",
       "      <td>1.119115</td>\n",
       "      <td>6.586730</td>\n",
       "      <td>16.992073</td>\n",
       "      <td>0.230089</td>\n",
       "      <td>0.500004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15002.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>41894.250000</td>\n",
       "      <td>74510.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.050000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>76327.000000</td>\n",
       "      <td>138994.000000</td>\n",
       "      <td>565.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.020000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>112814.500000</td>\n",
       "      <td>198012.000000</td>\n",
       "      <td>703.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>20.340000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>69.000000</td>\n",
       "      <td>149995.000000</td>\n",
       "      <td>249993.000000</td>\n",
       "      <td>849.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age         Income     LoanAmount   CreditScore  \\\n",
       "count  59306.000000   59306.000000   59306.000000  59306.000000   \n",
       "mean      40.492008   77943.901241  135176.603463    567.161366   \n",
       "std       14.950919   40121.124420   70906.740030    158.973285   \n",
       "min       18.000000   15002.000000    5000.000000    300.000000   \n",
       "25%       27.000000   41894.250000   74510.000000    429.000000   \n",
       "50%       39.000000   76327.000000  138994.000000    565.000000   \n",
       "75%       53.000000  112814.500000  198012.000000    703.000000   \n",
       "max       69.000000  149995.000000  249993.000000    849.000000   \n",
       "\n",
       "       MonthsEmployed  NumCreditLines  InterestRate      LoanTerm  \\\n",
       "count    59306.000000    59306.000000  59306.000000  59306.000000   \n",
       "mean        55.446903        2.538917     14.555326     36.018008   \n",
       "std         34.559096        1.119115      6.586730     16.992073   \n",
       "min          0.000000        1.000000      2.000000     12.000000   \n",
       "25%         25.000000        2.000000      9.050000     24.000000   \n",
       "50%         53.000000        3.000000     15.020000     36.000000   \n",
       "75%         85.000000        4.000000     20.340000     48.000000   \n",
       "max        119.000000        4.000000     25.000000     60.000000   \n",
       "\n",
       "           DTIRatio       Default  \n",
       "count  59306.000000  59306.000000  \n",
       "mean       0.506626      0.500000  \n",
       "std        0.230089      0.500004  \n",
       "min        0.100000      0.000000  \n",
       "25%        0.310000      0.000000  \n",
       "50%        0.510000      0.500000  \n",
       "75%        0.710000      1.000000  \n",
       "max        0.900000      1.000000  "
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling with SMOTE if we prefer to use it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important!!! This method conducts encoding and splitting (train/test) first so the next couple of elements need to be omitted. I also did not fully test the compatibility of the later code with SMOTE as I find downsampling more appropriate in this model's case due to the large enough sample even after the downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate features (X) and target variable (y)\n",
    "# X = df.drop('Default', axis=1)\n",
    "# y = df['Default']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9112023)\n",
    "\n",
    "# # Combine training and testing sets for encoding\n",
    "# combined_data = pd.concat([X_train, X_test])\n",
    "\n",
    "# # Encode categorical variables using OrdinalEncoder\n",
    "# ordinal_encoder = OrdinalEncoder()\n",
    "# combined_data_encoded = pd.DataFrame(ordinal_encoder.fit_transform(combined_data.select_dtypes(include=['object'])), columns=combined_data.select_dtypes(include=['object']).columns)\n",
    "\n",
    "# # Split the combined data back into training and testing sets\n",
    "# X_train_encoded = combined_data_encoded.iloc[:len(X_train), :]\n",
    "# X_test_encoded = combined_data_encoded.iloc[len(X_train):, :]\n",
    "\n",
    "# # Use SMOTE to oversample the minority class in the training set\n",
    "# smote = SMOTE(random_state=9112023)\n",
    "# X_train, y_train = smote.fit_resample(X_train_encoded, y_train)\n",
    "\n",
    "# # Print the counts of the target variable before and after oversampling\n",
    "# print(\"Class distribution after SMOTE:\", y_train.value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding categorical variables as numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numerical and categorical features\n",
    "numerical_X = df[['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed', 'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio']]\n",
    "categorical_X = df[['Education', 'EmploymentType', 'MaritalStatus', 'HasMortgage', 'HasDependents', 'LoanPurpose', 'HasCoSigner']]\n",
    "\n",
    "# Apply OrdinalEncoder to selected categorical variables\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "categorical_X_encoded = pd.DataFrame(ordinal_encoder.fit_transform(categorical_X), columns=categorical_X.columns)\n",
    "\n",
    "# Convert the entire DataFrame to numeric dtype\n",
    "categorical_X_encoded = categorical_X_encoded.astype('float')\n",
    "\n",
    "# Combine numerical and encoded categorical features\n",
    "X = pd.concat([numerical_X, categorical_X_encoded], axis=1)\n",
    "\n",
    "# Refreshing the DataFrame (df) such that it includes the encoded features\n",
    "df = pd.concat([X, df['Default']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>MonthsEmployed</th>\n",
       "      <th>NumCreditLines</th>\n",
       "      <th>InterestRate</th>\n",
       "      <th>LoanTerm</th>\n",
       "      <th>DTIRatio</th>\n",
       "      <th>Education</th>\n",
       "      <th>EmploymentType</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HasMortgage</th>\n",
       "      <th>HasDependents</th>\n",
       "      <th>LoanPurpose</th>\n",
       "      <th>HasCoSigner</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.492008</td>\n",
       "      <td>77943.901241</td>\n",
       "      <td>135176.603463</td>\n",
       "      <td>567.161366</td>\n",
       "      <td>55.446903</td>\n",
       "      <td>2.538917</td>\n",
       "      <td>14.555326</td>\n",
       "      <td>36.018008</td>\n",
       "      <td>0.506626</td>\n",
       "      <td>1.462786</td>\n",
       "      <td>1.554345</td>\n",
       "      <td>0.991333</td>\n",
       "      <td>0.486780</td>\n",
       "      <td>0.480626</td>\n",
       "      <td>1.983307</td>\n",
       "      <td>0.479142</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.950919</td>\n",
       "      <td>40121.124420</td>\n",
       "      <td>70906.740030</td>\n",
       "      <td>158.973285</td>\n",
       "      <td>34.559096</td>\n",
       "      <td>1.119115</td>\n",
       "      <td>6.586730</td>\n",
       "      <td>16.992073</td>\n",
       "      <td>0.230089</td>\n",
       "      <td>1.113357</td>\n",
       "      <td>1.112683</td>\n",
       "      <td>0.824950</td>\n",
       "      <td>0.499829</td>\n",
       "      <td>0.499629</td>\n",
       "      <td>1.417557</td>\n",
       "      <td>0.499569</td>\n",
       "      <td>0.500004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15002.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>41894.250000</td>\n",
       "      <td>74510.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.050000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>76327.000000</td>\n",
       "      <td>138994.000000</td>\n",
       "      <td>565.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.020000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>112814.500000</td>\n",
       "      <td>198012.000000</td>\n",
       "      <td>703.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>20.340000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>69.000000</td>\n",
       "      <td>149995.000000</td>\n",
       "      <td>249993.000000</td>\n",
       "      <td>849.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age         Income     LoanAmount   CreditScore  \\\n",
       "count  59306.000000   59306.000000   59306.000000  59306.000000   \n",
       "mean      40.492008   77943.901241  135176.603463    567.161366   \n",
       "std       14.950919   40121.124420   70906.740030    158.973285   \n",
       "min       18.000000   15002.000000    5000.000000    300.000000   \n",
       "25%       27.000000   41894.250000   74510.000000    429.000000   \n",
       "50%       39.000000   76327.000000  138994.000000    565.000000   \n",
       "75%       53.000000  112814.500000  198012.000000    703.000000   \n",
       "max       69.000000  149995.000000  249993.000000    849.000000   \n",
       "\n",
       "       MonthsEmployed  NumCreditLines  InterestRate      LoanTerm  \\\n",
       "count    59306.000000    59306.000000  59306.000000  59306.000000   \n",
       "mean        55.446903        2.538917     14.555326     36.018008   \n",
       "std         34.559096        1.119115      6.586730     16.992073   \n",
       "min          0.000000        1.000000      2.000000     12.000000   \n",
       "25%         25.000000        2.000000      9.050000     24.000000   \n",
       "50%         53.000000        3.000000     15.020000     36.000000   \n",
       "75%         85.000000        4.000000     20.340000     48.000000   \n",
       "max        119.000000        4.000000     25.000000     60.000000   \n",
       "\n",
       "           DTIRatio     Education  EmploymentType  MaritalStatus  \\\n",
       "count  59306.000000  59306.000000    59306.000000   59306.000000   \n",
       "mean       0.506626      1.462786        1.554345       0.991333   \n",
       "std        0.230089      1.113357        1.112683       0.824950   \n",
       "min        0.100000      0.000000        0.000000       0.000000   \n",
       "25%        0.310000      0.000000        1.000000       0.000000   \n",
       "50%        0.510000      1.000000        2.000000       1.000000   \n",
       "75%        0.710000      2.000000        3.000000       2.000000   \n",
       "max        0.900000      3.000000        3.000000       2.000000   \n",
       "\n",
       "        HasMortgage  HasDependents   LoanPurpose   HasCoSigner       Default  \n",
       "count  59306.000000   59306.000000  59306.000000  59306.000000  59306.000000  \n",
       "mean       0.486780       0.480626      1.983307      0.479142      0.500000  \n",
       "std        0.499829       0.499629      1.417557      0.499569      0.500004  \n",
       "min        0.000000       0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.000000       0.000000      1.000000      0.000000      0.000000  \n",
       "50%        0.000000       0.000000      2.000000      0.000000      0.500000  \n",
       "75%        1.000000       1.000000      3.000000      1.000000      1.000000  \n",
       "max        1.000000       1.000000      4.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (47444, 16) (47444,)\n",
      "Testing set shape: (11862, 16) (11862,)\n"
     ]
    }
   ],
   "source": [
    "# Defining explanatory and target variables\n",
    "\n",
    "y = df['Default']  \n",
    "\n",
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9112023)\n",
    "\n",
    "# Print the shapes of the sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                 int64\n",
      "Income              int64\n",
      "LoanAmount          int64\n",
      "CreditScore         int64\n",
      "MonthsEmployed      int64\n",
      "NumCreditLines      int64\n",
      "InterestRate      float64\n",
      "LoanTerm            int64\n",
      "DTIRatio          float64\n",
      "Education         float64\n",
      "EmploymentType    float64\n",
      "MaritalStatus     float64\n",
      "HasMortgage       float64\n",
      "HasDependents     float64\n",
      "LoanPurpose       float64\n",
      "HasCoSigner       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With StatsModels to have a neat summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.595213\n",
      "         Iterations 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                Default   No. Observations:                47444\n",
      "Model:                          Logit   Df Residuals:                    47427\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Fri, 12 Jan 2024   Pseudo R-squ.:                  0.1413\n",
      "Time:                        06:59:18   Log-Likelihood:                -28239.\n",
      "converged:                       True   LL-Null:                       -32886.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0121      0.010     -1.193      0.233      -0.032       0.008\n",
      "x1            -0.5872      0.011    -55.670      0.000      -0.608      -0.567\n",
      "x2            -0.3300      0.010    -32.115      0.000      -0.350      -0.310\n",
      "x3             0.2813      0.010     27.434      0.000       0.261       0.301\n",
      "x4            -0.1161      0.010    -11.420      0.000      -0.136      -0.096\n",
      "x5            -0.3422      0.010    -33.266      0.000      -0.362      -0.322\n",
      "x6             0.0975      0.010      9.589      0.000       0.078       0.117\n",
      "x7             0.4538      0.010     43.683      0.000       0.433       0.474\n",
      "x8            -0.0021      0.010     -0.210      0.833      -0.022       0.018\n",
      "x9             0.0625      0.010      6.159      0.000       0.043       0.082\n",
      "x10           -0.0800      0.010     -7.873      0.000      -0.100      -0.060\n",
      "x11            0.1471      0.010     14.460      0.000       0.127       0.167\n",
      "x12           -0.0222      0.010     -2.188      0.029      -0.042      -0.002\n",
      "x13           -0.0871      0.010     -8.577      0.000      -0.107      -0.067\n",
      "x14           -0.1236      0.010    -12.164      0.000      -0.143      -0.104\n",
      "x15           -0.0454      0.010     -4.471      0.000      -0.065      -0.025\n",
      "x16           -0.1468      0.010    -14.448      0.000      -0.167      -0.127\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "model = sm.Logit(y_train, sm.add_constant(X_train))\n",
    "result = model.fit()\n",
    "\n",
    "print(result.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model with the scikit package for further evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=9112023)\n",
    "\n",
    "# Fit the logistic regression model to the training data\n",
    "result_sklearn = model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm also scaling X_test to have it done before later steps\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6762771876580678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6782202966172305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "print(\"Precision:\", precision)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.680715838769025\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_test, y_test_pred)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.6794657762938231\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test, y_test_pred)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area Under the Receiver Operating Characteristic (ROC) Curve (AUC-ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.7420071616173065\n"
     ]
    }
   ],
   "source": [
    "auc_roc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "print(\"AUC-ROC:\", auc_roc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area Under the Precision-Recall Curve (AUC-PR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-PR: 0.7372814702951697\n"
     ]
    }
   ],
   "source": [
    "precision_curve, recall_curve, _ = precision_recall_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
    "auc_pr = auc(recall_curve, precision_curve)\n",
    "print(\"AUC-PR:\", auc_pr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3952 1931]\n",
      " [1909 4070]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
