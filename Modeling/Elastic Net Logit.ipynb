{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import seaborn \n",
    "import openpyxl\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, auc, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Loan_default.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances where Default is 1: 29653\n"
     ]
    }
   ],
   "source": [
    "default_count = df['Default'].sum()\n",
    "\n",
    "print(f\"Number of instances where Default is 1: {default_count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with class imbalance\n",
    "\n",
    "Using a binomial model, we assume a 0.5 probability of the outcome variable. As in our sample, we have a roughly 0.12 probability of default, we may consider balancing the sample such that the default probability of 0.5\n",
    "\n",
    "To do that, we randomly sample from the observations of no-default (downward) such that the default and no-default are matched in size."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling\n",
    "\n",
    "I do admit, this is wholly pulled from ChatGPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the majority and minority classes\n",
    "majority_class = df[df['Default'] == 0]\n",
    "minority_class = df[df['Default'] == 1]\n",
    "\n",
    "# Downsample the majority class to match the number of instances in the minority class\n",
    "downsampled_majority = majority_class.sample(n=len(minority_class), random_state=9112023)\n",
    "\n",
    "# Combine the downsampled majority class with the original minority class\n",
    "balanced_df = pd.concat([downsampled_majority, minority_class])\n",
    "\n",
    "y = balanced_df['Default']\n",
    "\n",
    "# Shuffle the rows to mix the classes\n",
    "df = balanced_df.sample(frac=1, random_state=9112023).reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying that the balanced_df is indeed holding a 50/50 split between default and no-default observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>MonthsEmployed</th>\n",
       "      <th>NumCreditLines</th>\n",
       "      <th>InterestRate</th>\n",
       "      <th>LoanTerm</th>\n",
       "      <th>DTIRatio</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.492008</td>\n",
       "      <td>77943.901241</td>\n",
       "      <td>135176.603463</td>\n",
       "      <td>567.161366</td>\n",
       "      <td>55.446903</td>\n",
       "      <td>2.538917</td>\n",
       "      <td>14.555326</td>\n",
       "      <td>36.018008</td>\n",
       "      <td>0.506626</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.950919</td>\n",
       "      <td>40121.124420</td>\n",
       "      <td>70906.740030</td>\n",
       "      <td>158.973285</td>\n",
       "      <td>34.559096</td>\n",
       "      <td>1.119115</td>\n",
       "      <td>6.586730</td>\n",
       "      <td>16.992073</td>\n",
       "      <td>0.230089</td>\n",
       "      <td>0.500004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15002.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>41894.250000</td>\n",
       "      <td>74510.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.050000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>76327.000000</td>\n",
       "      <td>138994.000000</td>\n",
       "      <td>565.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.020000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>112814.500000</td>\n",
       "      <td>198012.000000</td>\n",
       "      <td>703.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>20.340000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>69.000000</td>\n",
       "      <td>149995.000000</td>\n",
       "      <td>249993.000000</td>\n",
       "      <td>849.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age         Income     LoanAmount   CreditScore  \\\n",
       "count  59306.000000   59306.000000   59306.000000  59306.000000   \n",
       "mean      40.492008   77943.901241  135176.603463    567.161366   \n",
       "std       14.950919   40121.124420   70906.740030    158.973285   \n",
       "min       18.000000   15002.000000    5000.000000    300.000000   \n",
       "25%       27.000000   41894.250000   74510.000000    429.000000   \n",
       "50%       39.000000   76327.000000  138994.000000    565.000000   \n",
       "75%       53.000000  112814.500000  198012.000000    703.000000   \n",
       "max       69.000000  149995.000000  249993.000000    849.000000   \n",
       "\n",
       "       MonthsEmployed  NumCreditLines  InterestRate      LoanTerm  \\\n",
       "count    59306.000000    59306.000000  59306.000000  59306.000000   \n",
       "mean        55.446903        2.538917     14.555326     36.018008   \n",
       "std         34.559096        1.119115      6.586730     16.992073   \n",
       "min          0.000000        1.000000      2.000000     12.000000   \n",
       "25%         25.000000        2.000000      9.050000     24.000000   \n",
       "50%         53.000000        3.000000     15.020000     36.000000   \n",
       "75%         85.000000        4.000000     20.340000     48.000000   \n",
       "max        119.000000        4.000000     25.000000     60.000000   \n",
       "\n",
       "           DTIRatio       Default  \n",
       "count  59306.000000  59306.000000  \n",
       "mean       0.506626      0.500000  \n",
       "std        0.230089      0.500004  \n",
       "min        0.100000      0.000000  \n",
       "25%        0.310000      0.000000  \n",
       "50%        0.510000      0.500000  \n",
       "75%        0.710000      1.000000  \n",
       "max        0.900000      1.000000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling with SMOTE if we prefer to use it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important!!! This method conducts encoding and splitting (train/test) first so the next couple of elements need to be omitted. I also did not fully test the compatibility of the later code with SMOTE as I find downsampling more appropriate in this model's case due to the large enough sample even after the downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate features (X) and target variable (y)\n",
    "# X = df.drop('Default', axis=1)\n",
    "# y = df['Default']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9112023)\n",
    "\n",
    "# # Combine training and testing sets for encoding\n",
    "# combined_data = pd.concat([X_train, X_test])\n",
    "\n",
    "# # Encode categorical variables using OrdinalEncoder\n",
    "# ordinal_encoder = OrdinalEncoder()\n",
    "# combined_data_encoded = pd.DataFrame(ordinal_encoder.fit_transform(combined_data.select_dtypes(include=['object'])), columns=combined_data.select_dtypes(include=['object']).columns)\n",
    "\n",
    "# # Split the combined data back into training and testing sets\n",
    "# X_train_encoded = combined_data_encoded.iloc[:len(X_train), :]\n",
    "# X_test_encoded = combined_data_encoded.iloc[len(X_train):, :]\n",
    "\n",
    "# # Use SMOTE to oversample the minority class in the training set\n",
    "# smote = SMOTE(random_state=9112023)\n",
    "# X_train, y_train = smote.fit_resample(X_train_encoded, y_train)\n",
    "\n",
    "# # Print the counts of the target variable before and after oversampling\n",
    "# print(\"Class distribution after SMOTE:\", y_train.value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding categorical variables as numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numerical and categorical features\n",
    "numerical_X = df[['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed', 'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio']]\n",
    "categorical_X = df[['Education', 'EmploymentType', 'MaritalStatus', 'HasMortgage', 'HasDependents', 'LoanPurpose', 'HasCoSigner']]\n",
    "\n",
    "# Apply OrdinalEncoder to selected categorical variables\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "categorical_X_encoded = pd.DataFrame(ordinal_encoder.fit_transform(categorical_X), columns=categorical_X.columns)\n",
    "\n",
    "# Convert the entire DataFrame to numeric dtype\n",
    "categorical_X_encoded = categorical_X_encoded.astype('float')\n",
    "\n",
    "# Combine numerical and encoded categorical features\n",
    "X = pd.concat([numerical_X, categorical_X_encoded], axis=1)\n",
    "\n",
    "# Refreshing the DataFrame (df) such that it includes the encoded features\n",
    "df = pd.concat([X, df['Default']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>MonthsEmployed</th>\n",
       "      <th>NumCreditLines</th>\n",
       "      <th>InterestRate</th>\n",
       "      <th>LoanTerm</th>\n",
       "      <th>DTIRatio</th>\n",
       "      <th>Education</th>\n",
       "      <th>EmploymentType</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HasMortgage</th>\n",
       "      <th>HasDependents</th>\n",
       "      <th>LoanPurpose</th>\n",
       "      <th>HasCoSigner</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "      <td>59306.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.492008</td>\n",
       "      <td>77943.901241</td>\n",
       "      <td>135176.603463</td>\n",
       "      <td>567.161366</td>\n",
       "      <td>55.446903</td>\n",
       "      <td>2.538917</td>\n",
       "      <td>14.555326</td>\n",
       "      <td>36.018008</td>\n",
       "      <td>0.506626</td>\n",
       "      <td>1.462786</td>\n",
       "      <td>1.554345</td>\n",
       "      <td>0.991333</td>\n",
       "      <td>0.486780</td>\n",
       "      <td>0.480626</td>\n",
       "      <td>1.983307</td>\n",
       "      <td>0.479142</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.950919</td>\n",
       "      <td>40121.124420</td>\n",
       "      <td>70906.740030</td>\n",
       "      <td>158.973285</td>\n",
       "      <td>34.559096</td>\n",
       "      <td>1.119115</td>\n",
       "      <td>6.586730</td>\n",
       "      <td>16.992073</td>\n",
       "      <td>0.230089</td>\n",
       "      <td>1.113357</td>\n",
       "      <td>1.112683</td>\n",
       "      <td>0.824950</td>\n",
       "      <td>0.499829</td>\n",
       "      <td>0.499629</td>\n",
       "      <td>1.417557</td>\n",
       "      <td>0.499569</td>\n",
       "      <td>0.500004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15002.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>41894.250000</td>\n",
       "      <td>74510.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.050000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>76327.000000</td>\n",
       "      <td>138994.000000</td>\n",
       "      <td>565.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.020000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>112814.500000</td>\n",
       "      <td>198012.000000</td>\n",
       "      <td>703.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>20.340000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>69.000000</td>\n",
       "      <td>149995.000000</td>\n",
       "      <td>249993.000000</td>\n",
       "      <td>849.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age         Income     LoanAmount   CreditScore  \\\n",
       "count  59306.000000   59306.000000   59306.000000  59306.000000   \n",
       "mean      40.492008   77943.901241  135176.603463    567.161366   \n",
       "std       14.950919   40121.124420   70906.740030    158.973285   \n",
       "min       18.000000   15002.000000    5000.000000    300.000000   \n",
       "25%       27.000000   41894.250000   74510.000000    429.000000   \n",
       "50%       39.000000   76327.000000  138994.000000    565.000000   \n",
       "75%       53.000000  112814.500000  198012.000000    703.000000   \n",
       "max       69.000000  149995.000000  249993.000000    849.000000   \n",
       "\n",
       "       MonthsEmployed  NumCreditLines  InterestRate      LoanTerm  \\\n",
       "count    59306.000000    59306.000000  59306.000000  59306.000000   \n",
       "mean        55.446903        2.538917     14.555326     36.018008   \n",
       "std         34.559096        1.119115      6.586730     16.992073   \n",
       "min          0.000000        1.000000      2.000000     12.000000   \n",
       "25%         25.000000        2.000000      9.050000     24.000000   \n",
       "50%         53.000000        3.000000     15.020000     36.000000   \n",
       "75%         85.000000        4.000000     20.340000     48.000000   \n",
       "max        119.000000        4.000000     25.000000     60.000000   \n",
       "\n",
       "           DTIRatio     Education  EmploymentType  MaritalStatus  \\\n",
       "count  59306.000000  59306.000000    59306.000000   59306.000000   \n",
       "mean       0.506626      1.462786        1.554345       0.991333   \n",
       "std        0.230089      1.113357        1.112683       0.824950   \n",
       "min        0.100000      0.000000        0.000000       0.000000   \n",
       "25%        0.310000      0.000000        1.000000       0.000000   \n",
       "50%        0.510000      1.000000        2.000000       1.000000   \n",
       "75%        0.710000      2.000000        3.000000       2.000000   \n",
       "max        0.900000      3.000000        3.000000       2.000000   \n",
       "\n",
       "        HasMortgage  HasDependents   LoanPurpose   HasCoSigner       Default  \n",
       "count  59306.000000   59306.000000  59306.000000  59306.000000  59306.000000  \n",
       "mean       0.486780       0.480626      1.983307      0.479142      0.500000  \n",
       "std        0.499829       0.499629      1.417557      0.499569      0.500004  \n",
       "min        0.000000       0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.000000       0.000000      1.000000      0.000000      0.000000  \n",
       "50%        0.000000       0.000000      2.000000      0.000000      0.500000  \n",
       "75%        1.000000       1.000000      3.000000      1.000000      1.000000  \n",
       "max        1.000000       1.000000      4.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (47444, 16) (47444,)\n",
      "Testing set shape: (11862, 16) (11862,)\n"
     ]
    }
   ],
   "source": [
    "# Defining explanatory and target variables\n",
    "\n",
    "y = df['Default']  \n",
    "\n",
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9112023)\n",
    "\n",
    "# Print the shapes of the sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                 int64\n",
      "Income              int64\n",
      "LoanAmount          int64\n",
      "CreditScore         int64\n",
      "MonthsEmployed      int64\n",
      "NumCreditLines      int64\n",
      "InterestRate      float64\n",
      "LoanTerm            int64\n",
      "DTIRatio          float64\n",
      "Education         float64\n",
      "EmploymentType    float64\n",
      "MaritalStatus     float64\n",
      "HasMortgage       float64\n",
      "HasDependents     float64\n",
      "LoanPurpose       float64\n",
      "HasCoSigner       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With StatsModels to have a neat summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.5952436924147182\n",
      "            Iterations: 58\n",
      "            Function evaluations: 58\n",
      "            Gradient evaluations: 58\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                Default   No. Observations:                47444\n",
      "Model:                          Logit   Df Residuals:                    47427\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Fri, 12 Jan 2024   Pseudo R-squ.:                  0.1413\n",
      "Time:                        07:02:13   Log-Likelihood:                -28239.\n",
      "converged:                       True   LL-Null:                       -32886.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0121      0.010     -1.188      0.235      -0.032       0.008\n",
      "x1            -0.5871      0.011    -55.665      0.000      -0.608      -0.566\n",
      "x2            -0.3299      0.010    -32.110      0.000      -0.350      -0.310\n",
      "x3             0.2812      0.010     27.429      0.000       0.261       0.301\n",
      "x4            -0.1161      0.010    -11.414      0.000      -0.136      -0.096\n",
      "x5            -0.3421      0.010    -33.260      0.000      -0.362      -0.322\n",
      "x6             0.0974      0.010      9.584      0.000       0.077       0.117\n",
      "x7             0.4537      0.010     43.677      0.000       0.433       0.474\n",
      "x8            -0.0021      0.010     -0.205      0.837      -0.022       0.018\n",
      "x9             0.0625      0.010      6.153      0.000       0.043       0.082\n",
      "x10           -0.0799      0.010     -7.868      0.000      -0.100      -0.060\n",
      "x11            0.1471      0.010     14.454      0.000       0.127       0.167\n",
      "x12           -0.0221      0.010     -2.182      0.029      -0.042      -0.002\n",
      "x13           -0.0870      0.010     -8.571      0.000      -0.107      -0.067\n",
      "x14           -0.1235      0.010    -12.158      0.000      -0.143      -0.104\n",
      "x15           -0.0453      0.010     -4.466      0.000      -0.065      -0.025\n",
      "x16           -0.1467      0.010    -14.442      0.000      -0.167      -0.127\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/statsmodels/base/l1_solvers_common.py:71: ConvergenceWarning: QC check did not pass for 10 out of 17 parameters\n",
      "Try increasing solver accuracy or number of iterations, decreasing alpha, or switch solvers\n",
      "  warnings.warn(message, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/statsmodels/base/l1_solvers_common.py:144: ConvergenceWarning: Could not trim params automatically due to failed QC check. Trimming using trim_mode == 'size' will still work.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = sm.Logit(y_train, sm.add_constant(X_train)).fit_regularized(alpha=0.5, L1_wt=0.5)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model with the scikit package for further evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='elasticnet', solver='saga', random_state=9112023, l1_ratio=0.5, C=1.0)\n",
    "\n",
    "# Fit the logistic regression model to the training data\n",
    "result_sklearn = model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrete search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': [0.1,\n",
       "  0.30000000000000004,\n",
       "  0.5000000000000001,\n",
       "  0.7000000000000001,\n",
       "  0.9000000000000001,\n",
       "  1.1000000000000003]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step_2 = 0.01\n",
    "step_3 = 0.2\n",
    "#step_4 = 1\n",
    "#step_5 = 10\n",
    "#step_6 = 100\n",
    "\n",
    "param_grid_C = {\n",
    "    'C': np.concatenate([\n",
    "        #np.arange(0.01, 0.1 + step_2, step_2),\n",
    "        np.arange(0.1, 1 + step_3, step_3),\n",
    "        #np.arange(1, 10 + step_4, step_4),\n",
    "        #np.arange(10, 100 + step_5, step_5),\n",
    "        #np.arange(100, 1000 + step_6, step_6),\n",
    "    ]).tolist()\n",
    "}\n",
    "\n",
    "param_grid_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1_ratio': [0.1,\n",
       "  0.30000000000000004,\n",
       "  0.5000000000000001,\n",
       "  0.7000000000000001,\n",
       "  0.9000000000000001,\n",
       "  1.1000000000000003]}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "step_3 = 0.2\n",
    "\n",
    "param_grid_l1_ratio = {\n",
    "    'l1_ratio': np.concatenate([\n",
    "        np.arange(0.1, 1 + step_3, step_3),\n",
    "    ]).tolist()\n",
    "}\n",
    "\n",
    "param_grid_l1_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': [0.1,\n",
       "  0.30000000000000004,\n",
       "  0.5000000000000001,\n",
       "  0.7000000000000001,\n",
       "  0.9000000000000001,\n",
       "  1.1000000000000003],\n",
       " 'l1_ratio': [0.1,\n",
       "  0.30000000000000004,\n",
       "  0.5000000000000001,\n",
       "  0.7000000000000001,\n",
       "  0.9000000000000001,\n",
       "  1.1000000000000003]}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_param_grid = {}\n",
    "\n",
    "merged_param_grid.update(param_grid_C)\n",
    "\n",
    "merged_param_grid.update(param_grid_l1_ratio)\n",
    "\n",
    "merged_param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'l1_ratio' parameter of LogisticRegression must be a float in the range [0, 1] or None. Got 1.1000000000000003 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.6820672  0.68196181 0.68198289 0.68196181 0.68194073        nan\n",
      " 0.6820672  0.6820672  0.68204612 0.68202504 0.68196181        nan\n",
      " 0.6820672  0.6820672  0.6820672  0.68208827 0.68202504        nan\n",
      " 0.68208828 0.6820672  0.6820672  0.6820672  0.6820672         nan\n",
      " 0.68208828 0.6820672  0.6820672  0.6820672  0.6820672         nan\n",
      " 0.68208828 0.68208828 0.6820672  0.6820672  0.6820672         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.7000000000000001, 'l1_ratio': 0.1}\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='elasticnet', solver='saga', random_state=9112023)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(model, merged_param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted Best C: 0.7\n",
      "Formatted Best l1_ratio: 0.1\n"
     ]
    }
   ],
   "source": [
    "best_c_value = best_parameters['C']\n",
    "formatted_best_c = round(best_c_value, 2)  \n",
    "print(\"Formatted Best C:\", formatted_best_c)\n",
    "\n",
    "best_l1_ratio_value = best_parameters['l1_ratio']\n",
    "formatted_best_l1_ratio = round(best_l1_ratio_value, 2)  \n",
    "print(\"Formatted Best l1_ratio:\", formatted_best_l1_ratio)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_acc = 0\n",
    "\n",
    "# for i in range (1, 100):\n",
    "#     lasso_lambda = i/10\n",
    "#     model_iter = LogisticRegression(penalty='l1', C=1/lasso_lambda, solver='liblinear', random_state=9112023)\n",
    "#     model_iter.fit(X_train, y_train)\n",
    "    \n",
    "#     y_pred_iter = model_iter.predict(X_test)\n",
    "#     accuracy_iter = accuracy_score(y_test, y_pred_iter)\n",
    "#     if accuracy_iter > best_acc:\n",
    "#         best_acc = accuracy_iter\n",
    "#         lambda_best = lasso_lambda\n",
    "\n",
    "# C_best = 1/lambda_best\n",
    "# print(lambda_best)\n",
    "# print(C_best)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating fitting the model with optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='l1', C=formatted_best_c, solver='liblinear', random_state=9112023)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Transforming the test set with the scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Making predictions on the scaled test set\n",
    "y_test_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6763614904737818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6782739086971009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "print(\"Precision:\", precision)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.6808830908178625\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_test, y_test_pred)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.6795759953259327\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test, y_test_pred)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area Under the Receiver Operating Characteristic (ROC) Curve (AUC-ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.7420095781435945\n"
     ]
    }
   ],
   "source": [
    "auc_roc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "print(\"AUC-ROC:\", auc_roc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area Under the Precision-Recall Curve (AUC-PR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-PR: 0.737291069848898\n"
     ]
    }
   ],
   "source": [
    "precision_curve, recall_curve, _ = precision_recall_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
    "auc_pr = auc(recall_curve, precision_curve)\n",
    "print(\"AUC-PR:\", auc_pr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3952 1931]\n",
      " [1908 4071]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
